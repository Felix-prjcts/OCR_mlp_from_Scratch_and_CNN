{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95423667",
   "metadata": {},
   "source": [
    "# Perceptron Experiments\n",
    "\n",
    "Ce notebook permet de lancer des expériences systématiques sur un MLP (perceptron multi‑couches)\n",
    "pour comparer différentes architectures, fonctions d’activation et taux d’apprentissage.\n",
    "\n",
    "Il enregistre chaque run dans un dossier `models/run_.../` avec :\n",
    "- `metrics.json` (métriques et hyperparamètres)\n",
    "- `confusion_matrix.npy` (matrice de confusion sur le test)\n",
    "\n",
    "Le notebook `perceptron_report.ipynb` exploitera ces fichiers pour faire un résumé global."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1dcce9",
   "metadata": {},
   "source": [
    "##  Configuration & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2332d905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODELS_DIR = C:\\Users\\User\\mlp\\models\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, json, time\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# === Données ===\n",
    "MNIST_TRAIN_CSV = Path(\"data/mnist_train.csv\")\n",
    "MNIST_TEST_CSV  = Path(\"data/mnist_test.csv\")\n",
    "\n",
    "IMG_DIR_TRAIN = Path(\"data/training\")\n",
    "IMG_DIR_TEST  = Path(\"data/testing\")\n",
    "\n",
    "#CURATED_DIR = Path(\"C:/Users/User/PycharmProjects/pythonProject6/.venv/curated_data\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 3\n",
    "ACTIVATION = [\"relu\",\"sigmoid\"] \n",
    "\n",
    "LR_LIST   = [0.005, 0.01, 0.03]\n",
    "ARCH_LIST = [\n",
    "    [256, 128],\n",
    "    [256, 128, 64],\n",
    "    [256, 128, 64, 32],\n",
    "]\n",
    "\n",
    "MODELS_DIR = Path(\"models\")\n",
    "SAVE_WEIGHTS = False\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"MODELS_DIR =\", MODELS_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb6198",
   "metadata": {},
   "source": [
    "##  Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2789056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Chargement depuis MNIST CSV\n",
      "Shapes: (60000, 784) (10000, 784)\n",
      "NB_CLASSES = 10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "def load_from_mnist_csv(train_csv: Path, test_csv: Path):\n",
    "    if not train_csv.exists() or not test_csv.exists():\n",
    "        return None\n",
    "    print(\" Chargement depuis MNIST CSV\")\n",
    "    train = pd.read_csv(train_csv)\n",
    "    test  = pd.read_csv(test_csv)\n",
    "    X_train = (train.iloc[:, 1:].values.astype(np.float32) / 255.0)\n",
    "    y_train = train.iloc[:, 0].values.astype(int)\n",
    "    X_test  = (test.iloc[:, 1:].values.astype(np.float32)  / 255.0)\n",
    "    y_test  = test.iloc[:, 0].values.astype(int)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_from_image_dirs(train_dir: Path, test_dir: Path, size=(28, 28)):\n",
    "    if not train_dir.exists() or not test_dir.exists():\n",
    "        return None\n",
    "\n",
    "    def scan_split(root: Path):\n",
    "        X, y = [], []\n",
    "        for label in sorted([d for d in os.listdir(root) if (root / d).is_dir()]):\n",
    "            dpath = root / label\n",
    "            for fname in os.listdir(dpath):\n",
    "                f = dpath / fname\n",
    "                if not f.is_file():\n",
    "                    continue\n",
    "                try:\n",
    "                    with Image.open(f) as img:\n",
    "                        img = img.convert(\"L\")\n",
    "                        img = img.resize(size)\n",
    "                        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "                        X.append(arr.reshape(-1))\n",
    "                        y.append(int(label))\n",
    "                except Exception as e:\n",
    "                    print(\"Image ignorée:\", f, e)\n",
    "        if not X:\n",
    "            return None, None\n",
    "        return np.stack(X), np.array(y, dtype=int)\n",
    "\n",
    "    X_train, y_train = scan_split(train_dir)\n",
    "    X_test,  y_test  = scan_split(test_dir)\n",
    "    if X_train is None or X_test is None:\n",
    "        return None\n",
    "    print(\" Chargement depuis dossiers images training/testing\")\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_from_curated_data(curated_dir: Path, size=(28, 28)):\n",
    "    import cv2\n",
    "    if not curated_dir.exists():\n",
    "        return None\n",
    "\n",
    "    img_paths = []\n",
    "    for root, _, files in os.walk(curated_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                img_paths.append(Path(root) / f)\n",
    "    if not img_paths:\n",
    "        return None\n",
    "\n",
    "    X, y_raw = [], []\n",
    "    for p in img_paths:\n",
    "        parent = p.parent.name\n",
    "        if parent.isdigit():\n",
    "            label = int(parent)\n",
    "        else:\n",
    "            label = ord(p.name[0])\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, size)\n",
    "        X.append(img.reshape(-1).astype(np.float32) / 255.0)\n",
    "        y_raw.append(label)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y_raw = np.array(y_raw, dtype=int)\n",
    "\n",
    "    uniq = np.unique(y_raw)\n",
    "    remap = {lab: i for i, lab in enumerate(sorted(uniq))}\n",
    "    y = np.array([remap[v] for v in y_raw], dtype=int)\n",
    "\n",
    "    remap_path = curated_dir / \"label_remap.json\"\n",
    "    with open(remap_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"raw_labels\": list(map(int, uniq)),\n",
    "                   \"raw_to_idx\": {int(k): int(v) for k, v in remap.items()}}, f, indent=2)\n",
    "    print(\"Remap des labels sauvegardé dans\", remap_path)\n",
    "\n",
    "    rng = np.random.default_rng(123)\n",
    "    idx = rng.permutation(len(X))\n",
    "    split = int(0.8 * len(X))\n",
    "    tr, te = idx[:split], idx[split:]\n",
    "    X_train, y_train = X[tr], y[tr]\n",
    "    X_test,  y_test  = X[te], y[te]\n",
    "\n",
    "    print(f\" curated_data/ : {len(X_train)} train / {len(X_test)} test, classes={len(uniq)}\")\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = load_from_mnist_csv(MNIST_TRAIN_CSV, MNIST_TEST_CSV)\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    data = load_from_image_dirs(IMG_DIR_TRAIN, IMG_DIR_TEST)\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    data = load_from_curated_data(CURATED_DIR, size=(28, 28))\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    raise FileNotFoundError(\"Aucune source de données trouvée).\")\n",
    "\n",
    "\n",
    "train_split, test_split = load_data()\n",
    "X_train, y_train = train_split\n",
    "X_test, y_test   = test_split\n",
    "\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "NB_CLASSES = int(max(y_train.max(), y_test.max()) + 1)\n",
    "\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"NB_CLASSES =\", NB_CLASSES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6467c",
   "metadata": {},
   "source": [
    "##  Modèle MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "455c2e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self, input_size, nb_classes, hidden_layers,\n",
    "                 lr=0.05, epochs=3, batch_size=32, activation=\"relu\"):\n",
    "        self.input_size = int(input_size)\n",
    "        self.nb_classes = int(nb_classes)\n",
    "        self.hidden = list(hidden_layers)\n",
    "        self.lr = float(lr)\n",
    "        self.epochs = int(epochs)\n",
    "        self.batch_size = int(batch_size)\n",
    "        assert activation in (\"relu\", \"sigmoid\")\n",
    "        self.activation_name = activation\n",
    "\n",
    "        self.W = []\n",
    "        dims = [self.input_size] + self.hidden + [self.nb_classes]\n",
    "        for i in range(len(dims) - 1):\n",
    "            fan_in = dims[i]\n",
    "            if activation == \"relu\" and i < len(dims) - 2:\n",
    "                std = np.sqrt(2.0 / fan_in)\n",
    "            else:\n",
    "                std = np.sqrt(1.0 / fan_in)\n",
    "            self.W.append(rng.normal(0.0, std, size=(dims[i+1], fan_in + 1)))\n",
    "\n",
    "    @staticmethod\n",
    "    def _add_bias(x):\n",
    "        if x.ndim == 1:\n",
    "            x = x.reshape(-1, 1)\n",
    "        return np.vstack([x, np.ones((1, x.shape[1]), dtype=x.dtype)])\n",
    "\n",
    "    @staticmethod\n",
    "    def _sigmoid(z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    @staticmethod\n",
    "    def _relu(z):\n",
    "        return np.maximum(0.0, z)\n",
    "\n",
    "    @staticmethod\n",
    "    def _softmax(z):\n",
    "        z = z - np.max(z, axis=0, keepdims=True)\n",
    "        e = np.exp(z)\n",
    "        return e / np.sum(e, axis=0, keepdims=True)\n",
    "\n",
    "    def forward(self, X):\n",
    "        A = [self._add_bias(X)]\n",
    "        Zs = []\n",
    "        for i in range(len(self.hidden)):\n",
    "            Z = self.W[i] @ A[-1]\n",
    "            Zs.append(Z)\n",
    "            if self.activation_name == \"relu\":\n",
    "                H = self._relu(Z)\n",
    "            else:\n",
    "                H = self._sigmoid(Z)\n",
    "            A.append(self._add_bias(H))\n",
    "        Z = self.W[-1] @ A[-1]\n",
    "        Zs.append(Z)\n",
    "        Yhat = self._softmax(Z)\n",
    "        A.append(Yhat)\n",
    "        return Zs, A\n",
    "\n",
    "    def backward(self, Y_true, Zs, A):\n",
    "        grads = [None] * len(self.W)\n",
    "        delta = A[-1] - Y_true\n",
    "        grads[-1] = (delta @ A[-2].T) / Y_true.shape[1]\n",
    "        for i in range(len(self.hidden) - 1, -1, -1):\n",
    "            Wnext = self.W[i + 1][:, :-1]\n",
    "            if self.activation_name == \"relu\":\n",
    "                prime = (Zs[i] > 0).astype(Zs[i].dtype)\n",
    "            else:\n",
    "                H = A[i + 1][:-1, :]\n",
    "                prime = H * (1.0 - H)\n",
    "            delta = (Wnext.T @ delta) * prime\n",
    "            grads[i] = (delta @ A[i].T) / Y_true.shape[1]\n",
    "        return grads\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = X.astype(np.float32)\n",
    "        y = y.astype(int)\n",
    "        n = X.shape[0]\n",
    "        for epoch in range(self.epochs):\n",
    "            idx = np.random.permutation(n)\n",
    "            Xs = X[idx]\n",
    "            ys = y[idx]\n",
    "            for start in range(0, n, self.batch_size):\n",
    "                end = min(start + self.batch_size, n)\n",
    "                xb = Xs[start:end].T\n",
    "                yb = ys[start:end]\n",
    "                Y = np.zeros((self.nb_classes, len(yb)), dtype=np.float32)\n",
    "                Y[yb, np.arange(len(yb))] = 1.0\n",
    "                Zs, A = self.forward(xb)\n",
    "                grads = self.backward(Y, Zs, A)\n",
    "                for i in range(len(self.W)):\n",
    "                    self.W[i] -= self.lr * grads[i]\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = X.astype(np.float32)\n",
    "        _, A = self.forward(X.T)\n",
    "        return np.argmax(A[-1], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98e2e7c",
   "metadata": {},
   "source": [
    "##  Lancer les runs & journaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c4a62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Run: run_20251103_232347_lr0.005_layers256-128_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232347_lr0.005_layers256-128_relu\n",
      "\n",
      "=== Run: run_20251103_232409_lr0.005_layers256-128-64_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232409_lr0.005_layers256-128-64_relu\n",
      "\n",
      "=== Run: run_20251103_232432_lr0.005_layers256-128-64-32_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232432_lr0.005_layers256-128-64-32_relu\n",
      "\n",
      "=== Run: run_20251103_232455_lr0.01_layers256-128_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232455_lr0.01_layers256-128_relu\n",
      "\n",
      "=== Run: run_20251103_232516_lr0.01_layers256-128-64_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232516_lr0.01_layers256-128-64_relu\n",
      "\n",
      "=== Run: run_20251103_232539_lr0.01_layers256-128-64-32_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232539_lr0.01_layers256-128-64-32_relu\n",
      "\n",
      "=== Run: run_20251103_232602_lr0.03_layers256-128_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232602_lr0.03_layers256-128_relu\n",
      "\n",
      "=== Run: run_20251103_232624_lr0.03_layers256-128-64_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232624_lr0.03_layers256-128-64_relu\n",
      "\n",
      "=== Run: run_20251103_232647_lr0.03_layers256-128-64-32_relu ===\n",
      "Run sauvegardé dans models\\run_20251103_232647_lr0.03_layers256-128-64-32_relu\n",
      "\n",
      "=== Run: run_20251103_232712_lr0.005_layers256-128_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232712_lr0.005_layers256-128_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232735_lr0.005_layers256-128-64_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232735_lr0.005_layers256-128-64_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232759_lr0.005_layers256-128-64-32_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232759_lr0.005_layers256-128-64-32_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232827_lr0.01_layers256-128_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232827_lr0.01_layers256-128_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232858_lr0.01_layers256-128-64_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232858_lr0.01_layers256-128-64_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232923_lr0.01_layers256-128-64-32_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232923_lr0.01_layers256-128-64-32_sigmoid\n",
      "\n",
      "=== Run: run_20251103_232946_lr0.03_layers256-128_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_232946_lr0.03_layers256-128_sigmoid\n",
      "\n",
      "=== Run: run_20251103_233007_lr0.03_layers256-128-64_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_233007_lr0.03_layers256-128-64_sigmoid\n",
      "\n",
      "=== Run: run_20251103_233029_lr0.03_layers256-128-64-32_sigmoid ===\n",
      "Run sauvegardé dans models\\run_20251103_233029_lr0.03_layers256-128-64-32_sigmoid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>accuracy_train</th>\n",
       "      <th>nb_params</th>\n",
       "      <th>hidden_layers</th>\n",
       "      <th>activation</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>epochs</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>created_at</th>\n",
       "      <th>train_seconds</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.976583</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:26:47</td>\n",
       "      <td>21.772865</td>\n",
       "      <td>run_20251103_232624_lr0.03_layers256-128-64_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.978350</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:27:12</td>\n",
       "      <td>23.839410</td>\n",
       "      <td>run_20251103_232647_lr0.03_layers256-128-64-32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.969733</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:26:24</td>\n",
       "      <td>20.741346</td>\n",
       "      <td>run_20251103_232602_lr0.03_layers256-128_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.957117</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:26:02</td>\n",
       "      <td>22.172590</td>\n",
       "      <td>run_20251103_232539_lr0.01_layers256-128-64-32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.954067</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:25:39</td>\n",
       "      <td>21.944587</td>\n",
       "      <td>run_20251103_232516_lr0.01_layers256-128-64_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.943417</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:25:16</td>\n",
       "      <td>20.424950</td>\n",
       "      <td>run_20251103_232455_lr0.01_layers256-128_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.9405</td>\n",
       "      <td>0.943267</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:24:55</td>\n",
       "      <td>22.316060</td>\n",
       "      <td>run_20251103_232432_lr0.005_layers256-128-64-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.930500</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:24:32</td>\n",
       "      <td>21.519894</td>\n",
       "      <td>run_20251103_232409_lr0.005_layers256-128-64_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.9211</td>\n",
       "      <td>0.921433</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>relu</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:24:09</td>\n",
       "      <td>21.721941</td>\n",
       "      <td>run_20251103_232347_lr0.005_layers256-128_relu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.886917</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:30:07</td>\n",
       "      <td>20.459629</td>\n",
       "      <td>run_20251103_232946_lr0.03_layers256-128_sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.7529</td>\n",
       "      <td>0.749550</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:28:58</td>\n",
       "      <td>29.183779</td>\n",
       "      <td>run_20251103_232827_lr0.01_layers256-128_sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.7261</td>\n",
       "      <td>0.723883</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:30:29</td>\n",
       "      <td>20.660321</td>\n",
       "      <td>run_20251103_233007_lr0.03_layers256-128-64_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.5857</td>\n",
       "      <td>0.580133</td>\n",
       "      <td>235146</td>\n",
       "      <td>[256, 128]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:27:35</td>\n",
       "      <td>21.992271</td>\n",
       "      <td>run_20251103_232712_lr0.005_layers256-128_sigmoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2067</td>\n",
       "      <td>0.208717</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:29:23</td>\n",
       "      <td>23.668077</td>\n",
       "      <td>run_20251103_232858_lr0.01_layers256-128-64_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>242762</td>\n",
       "      <td>[256, 128, 64]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:27:59</td>\n",
       "      <td>23.177379</td>\n",
       "      <td>run_20251103_232735_lr0.005_layers256-128-64_s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.005</td>\n",
       "      <td>2025-11-03 23:28:27</td>\n",
       "      <td>26.611437</td>\n",
       "      <td>run_20251103_232759_lr0.005_layers256-128-64-3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2025-11-03 23:29:46</td>\n",
       "      <td>21.346814</td>\n",
       "      <td>run_20251103_232923_lr0.01_layers256-128-64-32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.112367</td>\n",
       "      <td>244522</td>\n",
       "      <td>[256, 128, 64, 32]</td>\n",
       "      <td>sigmoid</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.030</td>\n",
       "      <td>2025-11-03 23:30:51</td>\n",
       "      <td>21.303430</td>\n",
       "      <td>run_20251103_233029_lr0.03_layers256-128-64-32...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy  accuracy_train  nb_params       hidden_layers activation  \\\n",
       "0     0.9697        0.976583     242762      [256, 128, 64]       relu   \n",
       "1     0.9673        0.978350     244522  [256, 128, 64, 32]       relu   \n",
       "2     0.9643        0.969733     235146          [256, 128]       relu   \n",
       "3     0.9528        0.957117     244522  [256, 128, 64, 32]       relu   \n",
       "4     0.9508        0.954067     242762      [256, 128, 64]       relu   \n",
       "5     0.9424        0.943417     235146          [256, 128]       relu   \n",
       "6     0.9405        0.943267     244522  [256, 128, 64, 32]       relu   \n",
       "7     0.9311        0.930500     242762      [256, 128, 64]       relu   \n",
       "8     0.9211        0.921433     235146          [256, 128]       relu   \n",
       "9     0.8900        0.886917     235146          [256, 128]    sigmoid   \n",
       "10    0.7529        0.749550     235146          [256, 128]    sigmoid   \n",
       "11    0.7261        0.723883     242762      [256, 128, 64]    sigmoid   \n",
       "12    0.5857        0.580133     235146          [256, 128]    sigmoid   \n",
       "13    0.2067        0.208717     242762      [256, 128, 64]    sigmoid   \n",
       "14    0.1135        0.112367     242762      [256, 128, 64]    sigmoid   \n",
       "15    0.1135        0.112367     244522  [256, 128, 64, 32]    sigmoid   \n",
       "16    0.1135        0.112367     244522  [256, 128, 64, 32]    sigmoid   \n",
       "17    0.1135        0.112367     244522  [256, 128, 64, 32]    sigmoid   \n",
       "\n",
       "    batch_size  epochs  learning_rate           created_at  train_seconds  \\\n",
       "0           32       3          0.030  2025-11-03 23:26:47      21.772865   \n",
       "1           32       3          0.030  2025-11-03 23:27:12      23.839410   \n",
       "2           32       3          0.030  2025-11-03 23:26:24      20.741346   \n",
       "3           32       3          0.010  2025-11-03 23:26:02      22.172590   \n",
       "4           32       3          0.010  2025-11-03 23:25:39      21.944587   \n",
       "5           32       3          0.010  2025-11-03 23:25:16      20.424950   \n",
       "6           32       3          0.005  2025-11-03 23:24:55      22.316060   \n",
       "7           32       3          0.005  2025-11-03 23:24:32      21.519894   \n",
       "8           32       3          0.005  2025-11-03 23:24:09      21.721941   \n",
       "9           32       3          0.030  2025-11-03 23:30:07      20.459629   \n",
       "10          32       3          0.010  2025-11-03 23:28:58      29.183779   \n",
       "11          32       3          0.030  2025-11-03 23:30:29      20.660321   \n",
       "12          32       3          0.005  2025-11-03 23:27:35      21.992271   \n",
       "13          32       3          0.010  2025-11-03 23:29:23      23.668077   \n",
       "14          32       3          0.005  2025-11-03 23:27:59      23.177379   \n",
       "15          32       3          0.005  2025-11-03 23:28:27      26.611437   \n",
       "16          32       3          0.010  2025-11-03 23:29:46      21.346814   \n",
       "17          32       3          0.030  2025-11-03 23:30:51      21.303430   \n",
       "\n",
       "                                             run_name  \n",
       "0    run_20251103_232624_lr0.03_layers256-128-64_relu  \n",
       "1   run_20251103_232647_lr0.03_layers256-128-64-32...  \n",
       "2       run_20251103_232602_lr0.03_layers256-128_relu  \n",
       "3   run_20251103_232539_lr0.01_layers256-128-64-32...  \n",
       "4    run_20251103_232516_lr0.01_layers256-128-64_relu  \n",
       "5       run_20251103_232455_lr0.01_layers256-128_relu  \n",
       "6   run_20251103_232432_lr0.005_layers256-128-64-3...  \n",
       "7   run_20251103_232409_lr0.005_layers256-128-64_relu  \n",
       "8      run_20251103_232347_lr0.005_layers256-128_relu  \n",
       "9    run_20251103_232946_lr0.03_layers256-128_sigmoid  \n",
       "10   run_20251103_232827_lr0.01_layers256-128_sigmoid  \n",
       "11  run_20251103_233007_lr0.03_layers256-128-64_si...  \n",
       "12  run_20251103_232712_lr0.005_layers256-128_sigmoid  \n",
       "13  run_20251103_232858_lr0.01_layers256-128-64_si...  \n",
       "14  run_20251103_232735_lr0.005_layers256-128-64_s...  \n",
       "15  run_20251103_232759_lr0.005_layers256-128-64-3...  \n",
       "16  run_20251103_232923_lr0.01_layers256-128-64-32...  \n",
       "17  run_20251103_233029_lr0.03_layers256-128-64-32...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def evaluate_and_log(model, X_train, y_train, X_test, y_test, run_dir: Path, extra: dict | None = None):\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    yhat_train = model.predict(X_train)\n",
    "    yhat_test  = model.predict(X_test)\n",
    "\n",
    "    acc_train = float((yhat_train == y_train).mean())\n",
    "    acc_test  = float((yhat_test  == y_test).mean())\n",
    "\n",
    "    cm = confusion_matrix(y_test, yhat_test, labels=list(range(model.nb_classes)))\n",
    "    np.save(run_dir / \"confusion_matrix.npy\", cm)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": acc_test,\n",
    "        \"accuracy_train\": acc_train,\n",
    "        \"nb_params\": int(sum(W.size for W in model.W)),\n",
    "        \"hidden_layers\": model.hidden,\n",
    "        \"activation\": model.activation_name,\n",
    "        \"batch_size\": model.batch_size,\n",
    "        \"epochs\": model.epochs,\n",
    "        \"learning_rate\": model.lr,\n",
    "        \"created_at\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    }\n",
    "    if extra:\n",
    "        metrics.update(extra)\n",
    "\n",
    "    with open(run_dir / \"metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    if SAVE_WEIGHTS:\n",
    "        for i, W in enumerate(model.W):\n",
    "            np.save(run_dir / f\"W{i}.npy\", W)\n",
    "\n",
    "    print(\"Run sauvegardé dans\", run_dir)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "all_metrics = []\n",
    "for activation in [\"relu\", \"sigmoid\"]:\n",
    "    for lr in LR_LIST:\n",
    "        for arch in ARCH_LIST:\n",
    "            tag = f\"lr{lr}_layers{'-'.join(map(str, arch))}_{activation}\"\n",
    "            run_name = \"run_\" + datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"_\" + tag\n",
    "            run_dir = MODELS_DIR / run_name\n",
    "            print(\"\\n=== Run:\", run_name, \"===\")\n",
    "            \n",
    "            model = MLP(\n",
    "                INPUT_SIZE,\n",
    "                NB_CLASSES,\n",
    "                arch,\n",
    "                lr=float(lr),\n",
    "                epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                activation=activation,  \n",
    "            )\n",
    "\n",
    "            t0 = time.time()\n",
    "            model.fit(X_train, y_train)\n",
    "            duration = time.time() - t0\n",
    "\n",
    "            m = evaluate_and_log(\n",
    "                model, X_train, y_train, X_test, y_test, run_dir,\n",
    "                extra={\"train_seconds\": duration, \"run_name\": run_name}\n",
    "            )\n",
    "            all_metrics.append(m)\n",
    "\n",
    "            \n",
    "df_runs = pd.DataFrame(all_metrics)\n",
    "df_runs.sort_values(\"accuracy\", ascending=False, inplace=True)\n",
    "df_runs.reset_index(drop=True, inplace=True)\n",
    "df_runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85302a44",
   "metadata": {},
   "source": [
    "##  Visualisation rapide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadf18fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_runs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mdf_runs\u001b[49m.empty:\n\u001b[32m      3\u001b[39m     plt.figure()\n\u001b[32m      4\u001b[39m     plt.plot(df_runs[\u001b[33m\"\u001b[39m\u001b[33mlearning_rate\u001b[39m\u001b[33m\"\u001b[39m], df_runs[\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m], marker=\u001b[33m\"\u001b[39m\u001b[33mo\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_runs' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if not df_runs.empty:\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(df_runs[\"learning_rate\"], df_runs[\"accuracy\"], marker=\"o\", linestyle=\"-\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Learning rate (log)\")\n",
    "    plt.ylabel(\"Accuracy test\")\n",
    "    plt.title(\"Accuracy vs Learning rate\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Aucun run à afficher.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mlp (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
