{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05192a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\keras\\src\\export\\tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc0a2664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "MNIST_TRAIN_CSV = Path(\"data/mnist_train.csv\")\n",
    "MNIST_TEST_CSV  = Path(\"data/mnist_test.csv\")\n",
    "\n",
    "IMG_DIR_TRAIN = Path(\"data/training\")\n",
    "IMG_DIR_TEST  = Path(\"data/testing\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b43aeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Chargement depuis MNIST CSV\n",
      "Shapes: (60000, 784) (10000, 784)\n",
      "NB_CLASSES = 10\n",
      "[784]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from PIL import Image\n",
    "\n",
    "def load_from_mnist_csv(train_csv: Path, test_csv: Path):\n",
    "    if not train_csv.exists() or not test_csv.exists():\n",
    "        return None\n",
    "    print(\" Chargement depuis MNIST CSV\")\n",
    "    train = pd.read_csv(train_csv)\n",
    "    test  = pd.read_csv(test_csv)\n",
    "    X_train = (train.iloc[:, 1:].values.astype(np.float32) / 255.0)\n",
    "    y_train = train.iloc[:, 0].values.astype(int)\n",
    "    X_test  = (test.iloc[:, 1:].values.astype(np.float32)  / 255.0)\n",
    "    y_test  = test.iloc[:, 0].values.astype(int)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_from_image_dirs(train_dir: Path, test_dir: Path, size=(28, 28)):\n",
    "    if not train_dir.exists() or not test_dir.exists():\n",
    "        return None\n",
    "\n",
    "    def scan_split(root: Path):\n",
    "        X, y = [], []\n",
    "        for label in sorted([d for d in os.listdir(root) if (root / d).is_dir()]):\n",
    "            dpath = root / label\n",
    "            for fname in os.listdir(dpath):\n",
    "                f = dpath / fname\n",
    "                if not f.is_file():\n",
    "                    continue\n",
    "                try:\n",
    "                    with Image.open(f) as img:\n",
    "                        img = img.convert(\"L\")\n",
    "                        img = img.resize(size)\n",
    "                        arr = np.array(img, dtype=np.float32) / 255.0\n",
    "                        X.append(arr.reshape(-1))\n",
    "                        y.append(int(label))\n",
    "                except Exception as e:\n",
    "                    print(\"Image ignorée:\", f, e)\n",
    "        if not X:\n",
    "            return None, None\n",
    "        return np.stack(X), np.array(y, dtype=int)\n",
    "\n",
    "    X_train, y_train = scan_split(train_dir)\n",
    "    X_test,  y_test  = scan_split(test_dir)\n",
    "    if X_train is None or X_test is None:\n",
    "        return None\n",
    "    print(\" Chargement depuis dossiers images training/testing\")\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_from_curated_data(curated_dir: Path, size=(28, 28)):\n",
    "    import cv2\n",
    "    if not curated_dir.exists():\n",
    "        return None\n",
    "\n",
    "    img_paths = []\n",
    "    for root, _, files in os.walk(curated_dir):\n",
    "        for f in files:\n",
    "            if f.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                img_paths.append(Path(root) / f)\n",
    "    if not img_paths:\n",
    "        return None\n",
    "\n",
    "    X, y_raw = [], []\n",
    "    for p in img_paths:\n",
    "        parent = p.parent.name\n",
    "        if parent.isdigit():\n",
    "            label = int(parent)\n",
    "        else:\n",
    "            label = ord(p.name[0])\n",
    "        img = cv2.imread(str(p), cv2.IMREAD_GRAYSCALE)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, size)\n",
    "        X.append(img.reshape(-1).astype(np.float32) / 255.0)\n",
    "        y_raw.append(label)\n",
    "\n",
    "    X = np.stack(X)\n",
    "    y_raw = np.array(y_raw, dtype=int)\n",
    "\n",
    "    uniq = np.unique(y_raw)\n",
    "    remap = {lab: i for i, lab in enumerate(sorted(uniq))}\n",
    "    y = np.array([remap[v] for v in y_raw], dtype=int)\n",
    "\n",
    "    remap_path = curated_dir / \"label_remap.json\"\n",
    "    with open(remap_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"raw_labels\": list(map(int, uniq)),\n",
    "                   \"raw_to_idx\": {int(k): int(v) for k, v in remap.items()}}, f, indent=2)\n",
    "    print(\"Remap des labels sauvegardé dans\", remap_path)\n",
    "\n",
    "    rng = np.random.default_rng(123)\n",
    "    idx = rng.permutation(len(X))\n",
    "    split = int(0.8 * len(X))\n",
    "    tr, te = idx[:split], idx[split:]\n",
    "    X_train, y_train = X[tr], y[tr]\n",
    "    X_test,  y_test  = X[te], y[te]\n",
    "\n",
    "    print(f\" curated_data/ : {len(X_train)} train / {len(X_test)} test, classes={len(uniq)}\")\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = load_from_mnist_csv(MNIST_TRAIN_CSV, MNIST_TEST_CSV)\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    data = load_from_image_dirs(IMG_DIR_TRAIN, IMG_DIR_TEST)\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    data = load_from_curated_data(CURATED_DIR, size=(28, 28))\n",
    "    if data is not None:\n",
    "        return data\n",
    "\n",
    "    raise FileNotFoundError(\"Aucune source de données trouvée).\")\n",
    "\n",
    "\n",
    "train_split, test_split = load_data()\n",
    "X_train, y_train = train_split\n",
    "X_test, y_test   = test_split\n",
    "\n",
    "INPUT_SIZE = X_train.shape[1]\n",
    "NB_CLASSES = int(max(y_train.max(), y_test.max()) + 1)\n",
    "\n",
    "input_shape = [list(X_train.shape)[-1]]\n",
    "print(\"Shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"NB_CLASSES =\", NB_CLASSES)\n",
    "print(input_shape)\n",
    "print(X_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1b6918",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(units=256, activation='relu', input_shape=input_shape, kernel_initializer='he_normal'),\n",
    "    layers.Dense(units=128, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dense(units=64, activation='relu', kernel_initializer='he_normal'),\n",
    "    layers.Dense(NB_CLASSES, activation='softmax', kernel_initializer='glorot_normal'),\n",
    "])\n",
    "\n",
    "# Compiler le modèle avec SGD (équivalent aux mises à jour W -= lr * grad)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.030),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815d94b",
   "metadata": {},
   "source": [
    "test sans early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "464c99ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9022 - loss: 0.3381 - val_accuracy: 0.9367 - val_loss: 0.2074\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9568 - loss: 0.1443 - val_accuracy: 0.9623 - val_loss: 0.1152\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9694 - loss: 0.1028 - val_accuracy: 0.9659 - val_loss: 0.1060\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0790 - val_accuracy: 0.9694 - val_loss: 0.0963\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9815 - loss: 0.0629 - val_accuracy: 0.9731 - val_loss: 0.0822\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9844 - loss: 0.0523 - val_accuracy: 0.9754 - val_loss: 0.0746\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9878 - loss: 0.0417 - val_accuracy: 0.9767 - val_loss: 0.0712\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0344 - val_accuracy: 0.9739 - val_loss: 0.0776\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0280 - val_accuracy: 0.9746 - val_loss: 0.0746\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0232 - val_accuracy: 0.9771 - val_loss: 0.0777\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0186 - val_accuracy: 0.9799 - val_loss: 0.0665\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0145 - val_accuracy: 0.9800 - val_loss: 0.0683\n",
      "Epoch 13/20\n",
      "\u001b[1m 790/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0116"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- Évaluation sur le jeu de Test ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m test_results = model.evaluate(X_test, y_test, batch_size=\u001b[32m32\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:399\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m begin_step, end_step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    398\u001b[39m     callbacks.on_train_batch_begin(begin_step)\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    400\u001b[39m     callbacks.on_train_batch_end(end_step, logs)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:242\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    239\u001b[39m     iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    240\u001b[39m ):\n\u001b[32m    241\u001b[39m     opt_outputs = multi_step_on_iterator(iterator)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mopt_outputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    243\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m    244\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs.get_value()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\optional_ops.py:176\u001b[39m, in \u001b[36m_OptionalImpl.has_value\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgen_optional_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptional_has_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variant_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\mlp\\venv_mlp\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_optional_ops.py:172\u001b[39m, in \u001b[36moptional_has_value\u001b[39m\u001b[34m(optional, name)\u001b[39m\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m    171\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOptionalHasValue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptional\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m    175\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "print(\"\\n--- Évaluation sur le jeu de Test ---\")\n",
    "test_results = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss:     {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03497ca",
   "metadata": {},
   "source": [
    "Optimize the training to see the best accuracy we can get with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f19ca110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using early stopping to prevent overfitting\n",
    "from tensorflow.keras import layers, callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=5, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33abc74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0093 - val_accuracy: 0.9794 - val_loss: 0.0713\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0071 - val_accuracy: 0.9779 - val_loss: 0.0751\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0052 - val_accuracy: 0.9805 - val_loss: 0.0697\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0043 - val_accuracy: 0.9804 - val_loss: 0.0711\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.9812 - val_loss: 0.0694\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0024 - val_accuracy: 0.9802 - val_loss: 0.0724\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0019 - val_accuracy: 0.9814 - val_loss: 0.0722\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.9811 - val_loss: 0.0717\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.9815 - val_loss: 0.0735\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.9815 - val_loss: 0.0752\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22da7044ef0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using early stopping to prevent overfitting\n",
    "from tensorflow.keras import layers, callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.0001, # minimium amount of change to count as an improvement\n",
    "    patience=5, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5913cbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Évaluation sur le jeu de Test ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9812 - loss: 0.0694\n",
      "Test Loss:     0.0694\n",
      "Test Accuracy: 98.12%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Évaluation sur le jeu de Test ---\")\n",
    "test_results = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss:     {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "749da0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0236 - val_accuracy: 0.9756 - val_loss: 0.0899\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0301 - val_accuracy: 0.9774 - val_loss: 0.0798\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0215 - val_accuracy: 0.9785 - val_loss: 0.0779\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0129 - val_accuracy: 0.9791 - val_loss: 0.0864\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0062 - val_accuracy: 0.9796 - val_loss: 0.0782\n",
      "\n",
      "--- Évaluation sur le jeu de Test ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0899\n",
      "Test Loss:     0.0899\n",
      "Test Accuracy: 97.56%\n"
     ]
    }
   ],
   "source": [
    "#Comparaison rapide pour LR de 0.05\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.050),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "print(\"\\n--- Évaluation sur le jeu de Test ---\")\n",
    "test_results = model.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss:     {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4a12c",
   "metadata": {},
   "source": [
    "Changing optimizer and adding batchnormalisation and Adam opti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76388a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_opti = keras.Sequential([\n",
    "    # On sépare l'activation pour insérer la BN au milieu\n",
    "    layers.Dense(units=256, kernel_initializer='he_normal', use_bias=False), \n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    #layers.Dropout(0.2), le droupout baisse la performance ici donc on le commente\n",
    "\n",
    "    layers.Dense(units=128, kernel_initializer='he_normal', use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "    #layers.Dropout(0.2),\n",
    "\n",
    "    layers.Dense(units=64, kernel_initializer='he_normal', use_bias=False),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Activation('relu'),\n",
    "\n",
    "    # Pas de Batch juste avant le Softmax final\n",
    "    layers.Dense(NB_CLASSES, activation='softmax', kernel_initializer='glorot_normal')\n",
    "])\n",
    "\n",
    "model_opti.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3310afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9307 - loss: 0.2374 - val_accuracy: 0.9651 - val_loss: 0.1105\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9669 - loss: 0.1090 - val_accuracy: 0.9739 - val_loss: 0.0846\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.0836 - val_accuracy: 0.9762 - val_loss: 0.0751\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0675 - val_accuracy: 0.9770 - val_loss: 0.0738\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0534 - val_accuracy: 0.9824 - val_loss: 0.0607\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0480 - val_accuracy: 0.9827 - val_loss: 0.0551\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9865 - loss: 0.0405 - val_accuracy: 0.9764 - val_loss: 0.0761\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0377 - val_accuracy: 0.9821 - val_loss: 0.0624\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0341 - val_accuracy: 0.9813 - val_loss: 0.0654\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0321 - val_accuracy: 0.9812 - val_loss: 0.0664\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0286 - val_accuracy: 0.9822 - val_loss: 0.0622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x22da6342960>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_opti.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b452ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Évaluation sur le jeu de Test ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9827 - loss: 0.0551\n",
      "Test Loss:     0.0551\n",
      "Test Accuracy: 98.27%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Évaluation sur le jeu de Test ---\")\n",
    "test_results = model_opti.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss:     {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7fe377",
   "metadata": {},
   "source": [
    "pareil mais sans adams mais avec normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a41c50ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0257 - val_accuracy: 0.9853 - val_loss: 0.0473\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9939 - loss: 0.0200 - val_accuracy: 0.9859 - val_loss: 0.0467\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.9861 - val_loss: 0.0464\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0178 - val_accuracy: 0.9860 - val_loss: 0.0472\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0153 - val_accuracy: 0.9858 - val_loss: 0.0470\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.9859 - val_loss: 0.0463\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.9861 - val_loss: 0.0470\n",
      "\n",
      "--- Évaluation sur le jeu de Test ---\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0467\n",
      "Test Loss:     0.0467\n",
      "Test Accuracy: 98.59%\n"
     ]
    }
   ],
   "source": [
    "model_opti.compile(\n",
    "    optimizer=keras.optimizers.SGD(learning_rate=0.030),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_opti.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "print(\"\\n--- Évaluation sur le jeu de Test ---\")\n",
    "test_results = model_opti.evaluate(X_test, y_test, batch_size=32)\n",
    "\n",
    "print(f\"Test Loss:     {test_results[0]:.4f}\")\n",
    "print(f\"Test Accuracy: {test_results[1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1023c0",
   "metadata": {},
   "source": [
    "Conclusion : \n",
    "En gardant la meme architecture de batch et epochs que le meilleur modele codé a la main avec numpy, la meilleur accuracy avec keras en utilisant la sgd plutot que admas avec le meme lr et la batch noramlisation on monte a environ 98.6 d'accuracy sur le test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d12f1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mlp (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
